{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rot Studio Colab Backend\n",
        "Use this notebook to spin up the FastAPI + Diffusers backend on a free Google Colab GPU instance. Keep the runtime alive while the React app is calling it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Prep checklist\n",
        "1. In the left sidebar, upload this repo so that `/content/art-style-transfer/backend` exists (or git clone it).\n",
        "2. Switch the runtime to **GPU (T4/L4)** under `Runtime > Change runtime type`.\n",
        "3. Run the cells below **from top to bottom**. Keep the final tunnel cell running.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path('/content/art-style-transfer/backend')\n",
        "assert PROJECT_ROOT.exists(), f\"Backend folder not found at {PROJECT_ROOT}. Upload the repo first.\"\n",
        "PROJECT_ROOT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/art-style-transfer/backend\n",
        "pip install -q -r requirements.txt cloudflared\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) HuggingFace token\n",
        "Only required if a LoRA checkpoint is gated. Otherwise you can skip this cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# login(token=\"hf_xxx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "import sys\n",
        "sys.path.append(str(PROJECT_ROOT))\n",
        "from style_config import STYLE_PRESETS  # noqa\n",
        "\n",
        "cache_root = Path('/content/lora-cache')\n",
        "cache_root.mkdir(exist_ok=True)\n",
        "\n",
        "for preset in STYLE_PRESETS.values():\n",
        "    if not preset.lora_repo:\n",
        "        continue\n",
        "    print(f\"Downloading {preset.lora_repo}â€¦\")\n",
        "    snapshot_download(repo_id=preset.lora_repo, local_dir=cache_root / preset.lora_repo.replace('/', '_'))\n",
        "\n",
        "print('LoRA cache ready:', json.dumps([p.lora_repo for p in STYLE_PRESETS.values() if p.lora_repo], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "uvicorn_cmd = [\n",
        "    'uvicorn',\n",
        "    'app:app',\n",
        "    '--host', '0.0.0.0',\n",
        "    '--port', '8000',\n",
        "]\n",
        "\n",
        "server = subprocess.Popen(uvicorn_cmd, cwd=PROJECT_ROOT)\n",
        "print('Uvicorn PID:', server.pid)\n",
        "time.sleep(5)\n",
        "print('Health probe:')\n",
        "!curl -s http://127.0.0.1:8000/health\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cloudflared tunnel --url http://127.0.0.1:8000 --no-autoupdate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Stop the tunnel with the square \"Stop\" button when you're done. To restart, rerun the server cell followed by the tunnel cell.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
